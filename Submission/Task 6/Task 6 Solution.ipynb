{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-alpha0\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import tensorflow as tf\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1' # Mke model run on CPU, the GPU version is unstable \n",
    "print(tf.__version__)\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6 development:\n",
    "\n",
    "\n",
    "*LOAD PROCESSED IMAGES*\n",
    "\n",
    "* Load training set \n",
    "\n",
    "* Load test set\n",
    "\n",
    "\n",
    "*Model Creation*\n",
    "\n",
    "* Models :\n",
    "\n",
    "\n",
    "* 2 Hidden Layer NN + Batch normalization\n",
    "* 2 Hidden Layer NN + LASSO REGULARIZED MODEL\n",
    "* Commmite Neural networks \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "*Model evaluation*\n",
    "\n",
    "* Accuracy over Epochs \n",
    "* Loss over Epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting seeeds \n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load processed data  for Modelling \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_features = pickle.load(open( \"Dataset/processed/training_features.pickle\", \"rb\" ) )\n",
    "\n",
    "training_set_labels = pickle.load(open( \"Dataset/processed/training_labels.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20198"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set_features = pickle.load(open( \"Dataset/processed/test_features.pickle\", \"rb\" ) )\n",
    "\n",
    "testing_set_labels = pickle.load(open( \"Dataset/processed/test_labels.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4942"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing_set_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the TF.Dataset testing and training sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((2304,), ()), types: (tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_test_dataset=tf.data.Dataset.from_tensor_slices((testing_set_features,testing_set_labels)) # pass in data as tuple\n",
    "tf_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((2304,), ()), types: (tf.float32, tf.int8)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_training_dataset=tf.data.Dataset.from_tensor_slices((training_set_features,training_set_labels)) # pass in data as tuple\n",
    "tf_training_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced models \n",
    "\n",
    "* Batch Norm model (3-HIDDDEN LAYERS ) \n",
    "\n",
    "* LASSO MODEL (3 - HIDDEN LAYERS )  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network training parameters\n",
    "EPOCHS = 100 #number of training epochs\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 4 # number of outputs = number of emotions\n",
    "N_HIDDEN = 200\n",
    "initializer = tf.keras.initializers.GlorotNormal(seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm_model = tf.keras.models.Sequential( name = 'Batch Norm Model' )\n",
    "\n",
    "batch_norm_model.add(keras.layers.Dense (N_HIDDEN,input_shape = (2304,), name='dense_layer_1', \n",
    "                                         kernel_initializer = initializer,\n",
    "                                         activation='relu'))\n",
    "\n",
    "batch_norm_model.add(keras.layers.BatchNormalization()) #batch norm layer \n",
    "\n",
    "batch_norm_model.add(keras.layers.Dense (N_HIDDEN, name='dense_layer_2', \n",
    "                                         kernel_initializer = initializer,\n",
    "                                         activation='relu'))\n",
    "\n",
    "batch_norm_model.add(keras.layers.BatchNormalization()) # batch norm layer\n",
    "\n",
    "batch_norm_model.add(keras.layers.Dense( NB_CLASSES, name='output_layer', kernel_initializer = initializer, \n",
    "                                  activation = 'softmax'  ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Batch Norm Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_layer_1 (Dense)        (None, 200)               461000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_2 (Ba (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_layer_2 (Dense)        (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_3 (Ba (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 4)                 804       \n",
      "=================================================================\n",
      "Total params: 503,604\n",
      "Trainable params: 502,804\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(batch_norm_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save architecture\n",
    "\n",
    "#tf.keras.utils.plot_model(batch_norm_model,to_file='model architectures/batch_norm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm_model.compile(optimizer = 'ADAM', \n",
    "              loss = 'sparse_categorical_crossentropy',  # If LABELS---> Integers, then sparse is used. IF one-hot, then CE is used\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset shapes: ((2304,), ()), types: (tf.float32, tf.int8)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shuffle data\n",
    "shuffled_set=tf_training_dataset.shuffle(50_000)#.batch(64)    # This represents X_train and Y_train \n",
    "\n",
    "shuffled_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batched_training_set = shuffled_set.batch(64) #batch the dataset into 64,128, etc... batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "316/316 [==============================] - 3s 10ms/step - loss: 1.3027 - accuracy: 0.4207\n",
      "Epoch 2/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 1.2158 - accuracy: 0.4633\n",
      "Epoch 3/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 1.1791 - accuracy: 0.4827\n",
      "Epoch 4/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 1.1506 - accuracy: 0.4990\n",
      "Epoch 5/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 1.1220 - accuracy: 0.5178\n",
      "Epoch 6/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 1.1072 - accuracy: 0.5229\n",
      "Epoch 7/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 1.0912 - accuracy: 0.5356\n",
      "Epoch 8/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 1.0756 - accuracy: 0.5428\n",
      "Epoch 9/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 1.0553 - accuracy: 0.5531\n",
      "Epoch 10/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 1.0225 - accuracy: 0.5697\n",
      "Epoch 11/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 1.0123 - accuracy: 0.5773\n",
      "Epoch 12/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 1.0036 - accuracy: 0.5808\n",
      "Epoch 13/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.9759 - accuracy: 0.5926\n",
      "Epoch 14/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.9472 - accuracy: 0.6082\n",
      "Epoch 15/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.9321 - accuracy: 0.6140\n",
      "Epoch 16/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.9035 - accuracy: 0.6296\n",
      "Epoch 17/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.8702 - accuracy: 0.6467\n",
      "Epoch 18/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.8400 - accuracy: 0.6595\n",
      "Epoch 19/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.8183 - accuracy: 0.6681\n",
      "Epoch 20/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.8015 - accuracy: 0.6784\n",
      "Epoch 21/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 0.7660 - accuracy: 0.6941\n",
      "Epoch 22/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 0.7646 - accuracy: 0.6933\n",
      "Epoch 23/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.7505 - accuracy: 0.7000\n",
      "Epoch 24/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.7646 - accuracy: 0.6972\n",
      "Epoch 25/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.7351 - accuracy: 0.7061\n",
      "Epoch 26/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.7042 - accuracy: 0.7216\n",
      "Epoch 27/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.6789 - accuracy: 0.7358\n",
      "Epoch 28/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.6580 - accuracy: 0.7449\n",
      "Epoch 29/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.6396 - accuracy: 0.7540\n",
      "Epoch 30/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.6273 - accuracy: 0.7583\n",
      "Epoch 31/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.6027 - accuracy: 0.7710\n",
      "Epoch 32/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.5896 - accuracy: 0.7727\n",
      "Epoch 33/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.5737 - accuracy: 0.7820\n",
      "Epoch 34/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 0.5602 - accuracy: 0.7882\n",
      "Epoch 35/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 0.5558 - accuracy: 0.7895\n",
      "Epoch 36/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.5714 - accuracy: 0.7777\n",
      "Epoch 37/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.5635 - accuracy: 0.7829\n",
      "Epoch 38/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.5456 - accuracy: 0.7924\n",
      "Epoch 39/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 0.5805 - accuracy: 0.7763\n",
      "Epoch 40/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.5674 - accuracy: 0.7777\n",
      "Epoch 41/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.5231 - accuracy: 0.7993\n",
      "Epoch 42/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 0.5089 - accuracy: 0.8086\n",
      "Epoch 43/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.4896 - accuracy: 0.8164\n",
      "Epoch 44/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.4779 - accuracy: 0.8208\n",
      "Epoch 45/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.5028 - accuracy: 0.8063\n",
      "Epoch 46/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.5207 - accuracy: 0.8014\n",
      "Epoch 47/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.5902 - accuracy: 0.7666\n",
      "Epoch 48/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 0.5448 - accuracy: 0.7859\n",
      "Epoch 49/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.5171 - accuracy: 0.7989\n",
      "Epoch 50/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.4924 - accuracy: 0.8127\n",
      "Epoch 51/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.4727 - accuracy: 0.8200\n",
      "Epoch 52/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.4700 - accuracy: 0.8217\n",
      "Epoch 53/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.4468 - accuracy: 0.8308\n",
      "Epoch 54/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.4384 - accuracy: 0.8348\n",
      "Epoch 55/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.4283 - accuracy: 0.8403\n",
      "Epoch 56/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.4100 - accuracy: 0.8491\n",
      "Epoch 57/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.4055 - accuracy: 0.8491\n",
      "Epoch 58/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.3821 - accuracy: 0.8629\n",
      "Epoch 59/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.3795 - accuracy: 0.8580\n",
      "Epoch 60/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.3692 - accuracy: 0.8654\n",
      "Epoch 61/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.3721 - accuracy: 0.8631\n",
      "Epoch 62/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.3600 - accuracy: 0.8680\n",
      "Epoch 63/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.3481 - accuracy: 0.8737\n",
      "Epoch 64/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.3508 - accuracy: 0.8701\n",
      "Epoch 65/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.3437 - accuracy: 0.8734\n",
      "Epoch 66/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.3418 - accuracy: 0.8725\n",
      "Epoch 67/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.3732 - accuracy: 0.8593\n",
      "Epoch 68/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.5282 - accuracy: 0.7978\n",
      "Epoch 69/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.4430 - accuracy: 0.8282\n",
      "Epoch 70/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.3970 - accuracy: 0.8485\n",
      "Epoch 71/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.3693 - accuracy: 0.8587\n",
      "Epoch 72/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 0.3588 - accuracy: 0.8635\n",
      "Epoch 73/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.3491 - accuracy: 0.8686\n",
      "Epoch 74/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.3379 - accuracy: 0.8737\n",
      "Epoch 75/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.3257 - accuracy: 0.8795\n",
      "Epoch 76/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.3155 - accuracy: 0.8846\n",
      "Epoch 77/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.3101 - accuracy: 0.8863\n",
      "Epoch 78/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.3032 - accuracy: 0.8897\n",
      "Epoch 79/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.2957 - accuracy: 0.8900\n",
      "Epoch 80/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.2909 - accuracy: 0.8936\n",
      "Epoch 81/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.2810 - accuracy: 0.8973\n",
      "Epoch 82/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.2687 - accuracy: 0.9037\n",
      "Epoch 83/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.2735 - accuracy: 0.8990\n",
      "Epoch 84/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.2747 - accuracy: 0.9004\n",
      "Epoch 85/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.2593 - accuracy: 0.9053\n",
      "Epoch 86/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.2716 - accuracy: 0.9001\n",
      "Epoch 87/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.2577 - accuracy: 0.9065\n",
      "Epoch 88/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.2505 - accuracy: 0.9101\n",
      "Epoch 89/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 0.2447 - accuracy: 0.9112\n",
      "Epoch 90/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.2418 - accuracy: 0.9132\n",
      "Epoch 91/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.2333 - accuracy: 0.9155\n",
      "Epoch 92/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.2288 - accuracy: 0.9164\n",
      "Epoch 93/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 0.2274 - accuracy: 0.9165\n",
      "Epoch 94/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.2380 - accuracy: 0.9115\n",
      "Epoch 95/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 0.2392 - accuracy: 0.9112\n",
      "Epoch 96/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 0.2272 - accuracy: 0.9167\n",
      "Epoch 97/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 0.2262 - accuracy: 0.9176\n",
      "Epoch 98/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 0.2138 - accuracy: 0.9212\n",
      "Epoch 99/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.2156 - accuracy: 0.9197\n",
      "Epoch 100/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 0.2120 - accuracy: 0.9232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x281bc7a6eb8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we want to make our TensorBoard callback object:\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "NAME = \"Batch Norm Model\\\\\"\n",
    "now = datetime.now()\n",
    "\n",
    "logdir = \"tf_logs\\\\\"+ NAME + now.strftime(\"%Y%m%d-%H%M%S\") + \"\\\\\" \n",
    "\n",
    "tensorboard = TensorBoard(logdir)\n",
    "batch_norm_model.fit(shuffled_set.batch(64),shuffle=False, epochs=EPOCHS, verbose=VERBOSE, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 5ms/step - loss: 8.0754 - accuracy: 0.3153\n",
      "Test accuracy: 0.31525698\n"
     ]
    }
   ],
   "source": [
    "#evalute the model\n",
    "test_loss, test_acc = batch_norm_model.evaluate(tf_test_dataset.batch(64))\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1819166e-07, 4.2159173e-01, 4.8770826e-02, 5.2963728e-01],\n",
       "       [5.0300814e-02, 7.8212280e-12, 9.4806862e-01, 1.6304669e-03],\n",
       "       [4.1495891e-08, 1.0042367e-12, 1.2807253e-01, 8.7192744e-01],\n",
       "       ...,\n",
       "       [1.1617627e-08, 1.2579955e-10, 9.7261488e-01, 2.7385151e-02],\n",
       "       [7.7832124e-07, 1.7530478e-04, 2.9346445e-09, 9.9982399e-01],\n",
       "       [9.9753475e-01, 1.6431301e-07, 2.4651224e-03, 5.1496905e-08]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making prediction\n",
    "batch_norm_predictions = batch_norm_model.predict(tf_test_dataset.batch(32))\n",
    "batch_norm_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "batch_norm_model.save('trained models/my_batch_model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO Regularized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "LASSO_regularizer = tf.keras.regularizers.l1_l2( l1 = 0.0001, l2 = 0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = tf.keras.models.Sequential( name = 'LASSO MODEL' )\n",
    "\n",
    "lasso_model.add(keras.layers.Dense (N_HIDDEN,input_shape = (2304,), name='dense_layer_1', \n",
    "                                         kernel_initializer = initializer,\n",
    "                                         kernel_regularizer = LASSO_regularizer,\n",
    "                                         activation='relu'))\n",
    "\n",
    "lasso_model.add(keras.layers.Dense (N_HIDDEN, name='dense_layer_2', \n",
    "                                         kernel_initializer = initializer,\n",
    "                                         kernel_regularizer = LASSO_regularizer,\n",
    "                                         activation='relu'))\n",
    "\n",
    "lasso_model.add(keras.layers.Dense( NB_CLASSES, name='output_layer', kernel_initializer = initializer, \n",
    "                                  activation = 'softmax'  ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LASSO MODEL\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_layer_1 (Dense)        (None, 200)               461000    \n",
      "_________________________________________________________________\n",
      "dense_layer_2 (Dense)        (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 4)                 804       \n",
      "=================================================================\n",
      "Total params: 502,004\n",
      "Trainable params: 502,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(lasso_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model.compile(optimizer = 'ADAM', \n",
    "                    loss = 'sparse_categorical_crossentropy',  # If LABELS---> Integers, then sparse is used. IF one-hot, then CE is used\n",
    "                    metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we want to make our TensorBoard callback object:\n",
    "NAME = \"Lasso Model\\\\\"\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "logdir = \"tf_logs\\\\\"+ NAME + now.strftime(\"%Y%m%d-%H%M%S\") + \"\\\\\" \n",
    "\n",
    "tensorboard = TensorBoard(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "316/316 [==============================] - 2s 6ms/step - loss: 2.0092 - accuracy: 0.3734\n",
      "Epoch 2/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.5069 - accuracy: 0.4130\n",
      "Epoch 3/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.3884 - accuracy: 0.4269\n",
      "Epoch 4/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.3426 - accuracy: 0.4316\n",
      "Epoch 5/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.3180 - accuracy: 0.4411\n",
      "Epoch 6/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.3009 - accuracy: 0.4450\n",
      "Epoch 7/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2820 - accuracy: 0.4513\n",
      "Epoch 8/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2775 - accuracy: 0.4559\n",
      "Epoch 9/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2668 - accuracy: 0.4588\n",
      "Epoch 10/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2636 - accuracy: 0.4611\n",
      "Epoch 11/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2604 - accuracy: 0.4616\n",
      "Epoch 12/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2511 - accuracy: 0.4661\n",
      "Epoch 13/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2474 - accuracy: 0.4694\n",
      "Epoch 14/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2484 - accuracy: 0.4701\n",
      "Epoch 15/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2465 - accuracy: 0.4730\n",
      "Epoch 16/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2475 - accuracy: 0.4706\n",
      "Epoch 17/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2435 - accuracy: 0.4684\n",
      "Epoch 18/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2400 - accuracy: 0.4710\n",
      "Epoch 19/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2357 - accuracy: 0.4733\n",
      "Epoch 20/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2333 - accuracy: 0.4740\n",
      "Epoch 21/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2410 - accuracy: 0.4753\n",
      "Epoch 22/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2321 - accuracy: 0.4794\n",
      "Epoch 23/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2354 - accuracy: 0.4768\n",
      "Epoch 24/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2328 - accuracy: 0.4761\n",
      "Epoch 25/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2291 - accuracy: 0.4796\n",
      "Epoch 26/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2295 - accuracy: 0.4780\n",
      "Epoch 27/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2266 - accuracy: 0.4802\n",
      "Epoch 28/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2258 - accuracy: 0.4808\n",
      "Epoch 29/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2257 - accuracy: 0.4807\n",
      "Epoch 30/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2235 - accuracy: 0.4801\n",
      "Epoch 31/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2232 - accuracy: 0.4806\n",
      "Epoch 32/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2226 - accuracy: 0.4800\n",
      "Epoch 33/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2223 - accuracy: 0.4825\n",
      "Epoch 34/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2171 - accuracy: 0.4845\n",
      "Epoch 35/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2186 - accuracy: 0.4802\n",
      "Epoch 36/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2179 - accuracy: 0.4830\n",
      "Epoch 37/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2183 - accuracy: 0.4826\n",
      "Epoch 38/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 1.2179 - accuracy: 0.4836\n",
      "Epoch 39/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 1.2131 - accuracy: 0.4866\n",
      "Epoch 40/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2154 - accuracy: 0.4852\n",
      "Epoch 41/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2211 - accuracy: 0.4844\n",
      "Epoch 42/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2145 - accuracy: 0.4861\n",
      "Epoch 43/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2116 - accuracy: 0.4892\n",
      "Epoch 44/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2136 - accuracy: 0.4873\n",
      "Epoch 45/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2113 - accuracy: 0.4903\n",
      "Epoch 46/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 1.2125 - accuracy: 0.4852\n",
      "Epoch 47/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 1.2149 - accuracy: 0.4856\n",
      "Epoch 48/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2145 - accuracy: 0.4873\n",
      "Epoch 49/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2145 - accuracy: 0.4868\n",
      "Epoch 50/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2099 - accuracy: 0.4917\n",
      "Epoch 51/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2126 - accuracy: 0.4879\n",
      "Epoch 52/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2089 - accuracy: 0.4929\n",
      "Epoch 53/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2053 - accuracy: 0.4941\n",
      "Epoch 54/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2063 - accuracy: 0.4937\n",
      "Epoch 55/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2054 - accuracy: 0.4914\n",
      "Epoch 56/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2081 - accuracy: 0.4914\n",
      "Epoch 57/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2063 - accuracy: 0.4920\n",
      "Epoch 58/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2086 - accuracy: 0.4922\n",
      "Epoch 59/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2084 - accuracy: 0.4927\n",
      "Epoch 60/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2124 - accuracy: 0.4894\n",
      "Epoch 61/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2102 - accuracy: 0.4916\n",
      "Epoch 62/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 1.2085 - accuracy: 0.4933\n",
      "Epoch 63/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 1.2095 - accuracy: 0.4911\n",
      "Epoch 64/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 1.2059 - accuracy: 0.4933\n",
      "Epoch 65/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2058 - accuracy: 0.4935\n",
      "Epoch 66/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2081 - accuracy: 0.4907\n",
      "Epoch 67/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 1.2033 - accuracy: 0.4946\n",
      "Epoch 68/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2023 - accuracy: 0.4955\n",
      "Epoch 69/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2065 - accuracy: 0.4940\n",
      "Epoch 70/100\n",
      "316/316 [==============================] - 1s 5ms/step - loss: 1.2036 - accuracy: 0.4958\n",
      "Epoch 71/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2002 - accuracy: 0.4949\n",
      "Epoch 72/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2040 - accuracy: 0.4952\n",
      "Epoch 73/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2004 - accuracy: 0.4964\n",
      "Epoch 74/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.1999 - accuracy: 0.4973\n",
      "Epoch 75/100\n",
      "316/316 [==============================] - 1s 5ms/step - loss: 1.2008 - accuracy: 0.4993\n",
      "Epoch 76/100\n",
      "316/316 [==============================] - 2s 5ms/step - loss: 1.2018 - accuracy: 0.4963\n",
      "Epoch 77/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2015 - accuracy: 0.4966\n",
      "Epoch 78/100\n",
      "316/316 [==============================] - 1s 5ms/step - loss: 1.1988 - accuracy: 0.4977\n",
      "Epoch 79/100\n",
      "316/316 [==============================] - 1s 5ms/step - loss: 1.1952 - accuracy: 0.5005\n",
      "Epoch 80/100\n",
      "316/316 [==============================] - 1s 5ms/step - loss: 1.1964 - accuracy: 0.4982\n",
      "Epoch 81/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2013 - accuracy: 0.4979\n",
      "Epoch 82/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.2021 - accuracy: 0.4979\n",
      "Epoch 83/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.1994 - accuracy: 0.4986\n",
      "Epoch 84/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.1972 - accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.1985 - accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.1987 - accuracy: 0.5003\n",
      "Epoch 87/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.1996 - accuracy: 0.4994\n",
      "Epoch 88/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.1963 - accuracy: 0.5012\n",
      "Epoch 89/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.1951 - accuracy: 0.5021\n",
      "Epoch 90/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.1964 - accuracy: 0.4996\n",
      "Epoch 91/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.1942 - accuracy: 0.5039\n",
      "Epoch 92/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.1963 - accuracy: 0.5021\n",
      "Epoch 93/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.1974 - accuracy: 0.5014\n",
      "Epoch 94/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.1992 - accuracy: 0.4998\n",
      "Epoch 95/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.1919 - accuracy: 0.5041\n",
      "Epoch 96/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.1970 - accuracy: 0.4999\n",
      "Epoch 97/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.1906 - accuracy: 0.5022\n",
      "Epoch 98/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.1934 - accuracy: 0.5014\n",
      "Epoch 99/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.1960 - accuracy: 0.4992\n",
      "Epoch 100/100\n",
      "316/316 [==============================] - 1s 4ms/step - loss: 1.1913 - accuracy: 0.5021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2832709f240>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "lasso_model.fit(shuffled_set.batch(64), shuffle=False, epochs=EPOCHS, verbose=VERBOSE, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 4ms/step - loss: 1.2766 - accuracy: 0.4686\n",
      "Test accuracy: 0.46863618\n"
     ]
    }
   ],
   "source": [
    "#evalute the model\n",
    "test_loss, test_acc = lasso_model.evaluate(tf_test_dataset.batch(64))\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24362206, 0.2334331 , 0.17738259, 0.3455623 ],\n",
       "       [0.27760324, 0.10691798, 0.46112278, 0.154356  ],\n",
       "       [0.15562165, 0.49117714, 0.20603107, 0.14717007],\n",
       "       ...,\n",
       "       [0.27959532, 0.02071059, 0.2683908 , 0.43130326],\n",
       "       [0.17038801, 0.2510769 , 0.30984694, 0.26868817],\n",
       "       [0.2995861 , 0.57075614, 0.01312324, 0.11653463]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making prediction\n",
    "lasso_predictions = lasso_model.predict(tf_test_dataset.batch(64))\n",
    "lasso_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "lasso_model.save('trained models/my_lasso_model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF NOTEBOOK "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULTS CAN BE SEEN WITH TENSORBOARD and in the Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
